<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="TODO">
  <meta name="keywords" content="Imitation Learning">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Knowledge-Driven Imitation Learning</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script> -->
  <!-- <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script> -->


  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <!-- <link rel="icon" href="./static/images/favicon.svg"> -->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<!-- <nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div>

  </div>
</nav> -->


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Knowledge-Driven Imitation Learning:
            Enabling Generalization Across Diverse Conditions</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://github.com/mioam">Zhuochen Miao</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://lyuj1998.github.io/">Jun Lv</a><sup>1,3</sup>,</span>
            <span class="author-block">
               <a href="https://tonyfang.net/">Hongjie Fang</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://github.com/EricJin2002">Yang Jin</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="https://www.mvig.org/">Cewu Lu</a><sup>1,2,3</sup></span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Shanghai Jiao Tong University,</span>
            <span class="author-block"><sup>2</sup>Shanghai Innovation Institution, Shanghai, CHINA,</span>
            <span class="author-block"><sup>3</sup>Shanghai Noematrix Intelligence Technology Ltd.</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/mioam/KnowledgeIL"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
                </span> -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster=""  controls playsinline height="100%" preload="none">
        <source src="./static/videos/Knowledge-Driven_Imitation_Learning.mp4"
                type="video/mp4">
      </video>
    </div>
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Imitation learning has emerged as a powerful
            paradigm in robot manipulation, yet its generalization capability
            remains constrained by object-specific dependencies in limited
            expert demonstrations. To address this challenge, we propose
            knowledge-driven imitation learning, a framework that lever
           ages external structural semantic knowledge to abstract object
            representations within the same category. We introduce a novel
            semantic keypoint graph as a knowledge template and develop a
            coarse-to-fine template-matching algorithm that optimizes both
            structural consistency and semantic similarity. Evaluated on
            three real-world robotic manipulation tasks, our method achieves
            superior performance, surpassing image-based diffusion policies
            with only one-quarter of the expert demonstrations. Extensive
            experiments further demonstrate its robustness across novel
            objects, backgrounds, and lighting conditions. This work pioneers
            a knowledge-driven approach to data-efficient robotic learning in
            real-world settings.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>



<section class="section">
    <div class="container">
      
      <div class="column is-centered has-text-centered">
        <h2 class="title is-3">Pipeline</h2>
      </div>
      <div style="width: 50%; margin: auto;">
        <img src="./static/images/teaser.png"/>
        <p >
          Given an RGB-D image as input, the system generates a knowledge template for a specific object. This template is then matched to the demonstration, and the policy is learned based on the matching results. When encountering novel objects, the learned policy can be transferred, enabling generalization to new scenarios.
        </p>
      </div>
  </div>
</section>

<section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column">
          <h2 class="title is-3">Experiments</h2>
        </div>
      </div>
      <p>
        We present videos below that showcase our method's performance on different tasks, including examples of both successes and failures. These videos are played back at 5x speed. The gripper opening and closing sections were not included 
      </p>

      <div class="select">
        <select id="mySelect">
          <option value="0">Seen objects</option>
          <option value="1">Novel objects</option>
          <option value="2">Novel Background</option>
          <option value="3">Novel Light</option>
        </select>
      </div>

      <div class="is-centered has-text-centered indexed-div" >
        <h2 class="subtitle">Seen objects</h2>
        <div class="carousel results-carousel" data-name="mug40" data-num="20"></div>
        <div class="carousel results-carousel" data-name="tool20" data-num="25"></div>
      </div>

      <div class="is-centered has-text-centered indexed-div" >
        <h2 class="subtitle">Novel objects</h2>
        <div class="carousel results-carousel" data-name="novelobj_mug40" data-num="10"></div>
        <div class="carousel results-carousel" data-name="novelobj_tool20" data-num="10"></div>
      </div>

      <div class="is-centered has-text-centered indexed-div" >
        <h2 class="subtitle">Novel Background</h2>
        <div class="carousel results-carousel" data-name="background mug40" data-num="20"></div>
      </div>

      <div class="is-centered has-text-centered indexed-div" >
        <h2 class="subtitle">Novel Light</h2>
        <div class="carousel results-carousel" data-name="light mug40" data-num="20"></div>
      </div>
  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@inproceedings{miao2025Knowledge,
  title={Knowledge-Driven Imitation Learning: Enabling Generalization Across Diverse Conditions},
  author={Miao, Zhuochen and Lv, Jun and Fang, Hongjie and Jin, Yang and Lu, Cewu},
  booktitle={2025 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  year={2025},
  organization={IEEE}
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is adapt from <a href="https://github.com/nerfies/nerfies.github.io">nerfies</a>.
            
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>


</body>
</html>
